name: Run GPU Integration Tests

on:
  push:
    branches:
     - main
  pull_request:
  workflow_dispatch:

env:
  ACTIONS_RUNNER_DEBUG: true
  ACTIONS_STEP_DEBUG: true

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  pytorch-integration-local:
    runs-on: [single-gpu, nvidia-gpu, t4, ci]
    env:
      AWS_REGION: us-east-1
    steps:
    - name: Set up Python 3.11
      uses: actions/setup-python@v2
      with:
        python-version: 3.11
    - name: Install hub
      run: pip install -U "huggingface_hub[cli]"
    - name: Download dummy model
      run: |
        huggingface-cli download hf-internal-testing/tiny-random-distilbert --local-dir /mnt/hf_cache/distilbert && \
        ls /mnt/hf_cache
    - uses: actions/checkout@v4.1.1
    - name: Docker Setup Buildx
      uses: docker/setup-buildx-action@v3.0.0
    - name: Docker Build
      run: make inference-pytorch-gpu
    - name: List images
      run: docker images
    - name: Install hub
      run: pip install -U "huggingface_hub[cli]"
    - name: Download dummy model
      run: |
        huggingface-cli download hf-internal-testing/tiny-random-distilbert --local-dir /mnt/hf_cache/distilbert && \
        ls /mnt/hf_cache
    - name: Test model path
      run: |
        docker run \
          --gpus all \
          -v /tmp/distilbert:/tmp/distilbert \
          --entrypoint /bin/sh \
          integration-test-pytorch:gpu \
          -c "ls /tmp/distilbert"
    - name: Stop container
      run: make stop-all
    - name: Container dry run
      run: |
        docker run --gpus all \
          -v /tmp/distilbert:/tmp/distilbert \
          -e HF_MODEL_DIR=/tmp/distilbert \
          -e HF_TASK=text-classification \
          integration-test-pytorch:gpu
    - name: Stop container
      run: make stop-all
    - name: Set up Python 3.11
      uses: actions/setup-python@v2
      with:
        python-version: 3.11
    - name: Install tox & uv
      run: pip install uv tox
    - name: Run local integration tests
      run: tox -e torch-integration-local-gpu
  pytorch-integration-remote:
    runs-on: [single-gpu, nvidia-gpu, t4, ci]
    env:
      AWS_REGION: us-east-1
    steps:
    - uses: actions/checkout@v4.1.1
    - name: Docker Setup Buildx
      uses: docker/setup-buildx-action@v3.0.0
    - name: Docker Build
      run: make inference-pytorch-gpu
    - name: List images
      run: docker images
    - name: Set up Python 3.11
      uses: actions/setup-python@v2
      with:
        python-version: 3.11
    - name: Install tox & uv
      run: pip install uv tox
    - name: Run remote integration tests
      run: tox -e torch-integration-remote-gpu -- -n 4