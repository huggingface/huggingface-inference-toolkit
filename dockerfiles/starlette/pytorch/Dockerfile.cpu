FROM huggingface/transformers-inference:4.24.0-pt1.13-cpu

# install starlette framework
COPY starlette_requirements.txt /tmp/requirements.txt
RUN pip install  --no-cache-dir -r /tmp/requirements.txt && rm /tmp/requirements.txt

# Think about a better solution -> base contaienr has pt 1.13. thats why need below 0.14
RUN pip install  --no-cache-dir sentence_transformers torchvision~="0.14.0" diffusers=="0.9.0" accelerate=="0.15.0"

# Add upgrade due to issue in base container upgrade https://github.com/mamba-org/mamba/issues/2170
RUN pip install transformers==4.25.1  --no-cache-dir --upgrade 

# copy application
COPY src/huggingface_inference_toolkit huggingface_inference_toolkit
COPY src/huggingface_inference_toolkit/webservice_starlette.py webservice_starlette.py

# run app
ENTRYPOINT ["uvicorn", "webservice_starlette:app", "--host", "0.0.0.0", "--port", "5000"]


